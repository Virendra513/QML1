{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355fd117",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# 1. Imports\n",
    "# ===============================\n",
    "\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from qiskit import QuantumCircuit\n",
    "from qiskit.quantum_info import Statevector, Pauli\n",
    "\n",
    "\n",
    "# ===============================\n",
    "# 2. Quantum Feature Map\n",
    "# ===============================\n",
    "\n",
    "def quantum_feature_map(x):\n",
    "    \"\"\"\n",
    "    Fixed quantum circuit used only for feature preparation\n",
    "    \"\"\"\n",
    "    n_qubits = len(x)\n",
    "    qc = QuantumCircuit(n_qubits)\n",
    "\n",
    "    # Angle encoding\n",
    "    for i in range(n_qubits):\n",
    "        qc.ry(x[i], i)\n",
    "        qc.rz(x[i], i)\n",
    "\n",
    "    # Linear entanglement\n",
    "    for i in range(n_qubits - 1):\n",
    "        qc.cx(i, i + 1)\n",
    "\n",
    "    return qc\n",
    "\n",
    "\n",
    "def extract_quantum_features(x):\n",
    "    \"\"\"\n",
    "    Extract expectation-value-based quantum features\n",
    "    \"\"\"\n",
    "    qc = quantum_feature_map(x)\n",
    "    state = Statevector.from_instruction(qc)\n",
    "\n",
    "    features = []\n",
    "\n",
    "    # ⟨Z_i⟩\n",
    "    for i in range(len(x)):\n",
    "        pauli = ['I'] * len(x)\n",
    "        pauli[i] = 'Z'\n",
    "        features.append(\n",
    "            np.real(state.expectation_value(Pauli(''.join(pauli))))\n",
    "        )\n",
    "\n",
    "    # ⟨Z_i Z_{i+1}⟩\n",
    "    for i in range(len(x) - 1):\n",
    "        pauli = ['I'] * len(x)\n",
    "        pauli[i] = 'Z'\n",
    "        pauli[i + 1] = 'Z'\n",
    "        features.append(\n",
    "            np.real(state.expectation_value(Pauli(''.join(pauli))))\n",
    "        )\n",
    "\n",
    "    return np.array(features)\n",
    "\n",
    "\n",
    "# ===============================\n",
    "# 3. Training Pipeline\n",
    "# ===============================\n",
    "\n",
    "def train_pipeline(X, y, model_dir=\"models\"):\n",
    "    \"\"\"\n",
    "    Train full hybrid QML pipeline and save artifacts\n",
    "    \"\"\"\n",
    "\n",
    "    # ---- PCA ----\n",
    "    pca = PCA(n_components=8)\n",
    "    X_pca = pca.fit_transform(X)\n",
    "\n",
    "    # ---- Scaling to [0, π] ----\n",
    "    scaler = MinMaxScaler(feature_range=(0, np.pi))\n",
    "    X_scaled = scaler.fit_transform(X_pca)\n",
    "\n",
    "    # ---- Quantum feature extraction ----\n",
    "    Q_features = np.array([\n",
    "        extract_quantum_features(x) for x in X_scaled\n",
    "    ])\n",
    "\n",
    "    # ---- Train / test split ----\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        Q_features, y, test_size=0.2, random_state=42\n",
    "    )\n",
    "\n",
    "    # ---- Classical regression ----\n",
    "    regressor = RandomForestRegressor(\n",
    "        n_estimators=200,\n",
    "        max_depth=10,\n",
    "        random_state=42\n",
    "    )\n",
    "    regressor.fit(X_train, y_train)\n",
    "\n",
    "    # ---- Evaluation ----\n",
    "    y_pred = regressor.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    print(f\"[TRAINING] Test MSE: {mse:.4f}\")\n",
    "\n",
    "    # ---- Save artifacts ----\n",
    "    joblib.dump(pca, f\"{model_dir}/pca.pkl\")\n",
    "    joblib.dump(scaler, f\"{model_dir}/scaler.pkl\")\n",
    "    joblib.dump(regressor, f\"{model_dir}/regressor.pkl\")\n",
    "\n",
    "    print(\"[TRAINING] Model artifacts saved\")\n",
    "\n",
    "    return mse\n",
    "\n",
    "\n",
    "# ===============================\n",
    "# 4. Inference Pipeline\n",
    "# ===============================\n",
    "\n",
    "def load_pipeline(model_dir=\"models\"):\n",
    "    \"\"\"\n",
    "    Load trained pipeline components\n",
    "    \"\"\"\n",
    "    pca = joblib.load(f\"{model_dir}/pca.pkl\")\n",
    "    scaler = joblib.load(f\"{model_dir}/scaler.pkl\")\n",
    "    regressor = joblib.load(f\"{model_dir}/regressor.pkl\")\n",
    "\n",
    "    return pca, scaler, regressor\n",
    "\n",
    "\n",
    "def predict(X_new, pca, scaler, regressor):\n",
    "    \"\"\"\n",
    "    End-to-end inference on new data\n",
    "    \"\"\"\n",
    "\n",
    "    # Same preprocessing as training\n",
    "    X_pca = pca.transform(X_new)\n",
    "    X_scaled = scaler.transform(X_pca)\n",
    "\n",
    "    # Quantum feature preparation\n",
    "    Q_features = np.array([\n",
    "        extract_quantum_features(x) for x in X_scaled\n",
    "    ])\n",
    "\n",
    "    # Prediction\n",
    "    return regressor.predict(Q_features)\n",
    "\n",
    "\n",
    "# ===============================\n",
    "# 5. Main (Example Usage)\n",
    "# ===============================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # ---- Dummy dataset ----\n",
    "    N = 10000\n",
    "    X = np.random.rand(N, 40)\n",
    "    y = np.sum(X[:, :5], axis=1) + 0.1 * np.random.randn(N)\n",
    "\n",
    "    # ---- Train ----\n",
    "    train_pipeline(X, y)\n",
    "\n",
    "    # ---- Load pipeline ----\n",
    "    pca, scaler, regressor = load_pipeline()\n",
    "\n",
    "    # ---- Inference ----\n",
    "    X_new = np.random.rand(5, 40)\n",
    "    predictions = predict(X_new, pca, scaler, regressor)\n",
    "\n",
    "    print(\"[INFERENCE] Predictions:\", predictions)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
